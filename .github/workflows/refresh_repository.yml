name: Refresh Upstream and Notify API

on:
  schedule:
    - cron: '0 0 * * *' # Runs every day
  push:
    branches:
      - master
  workflow_dispatch: # Allows manual triggering

permissions:
  contents: write
  actions: write

jobs:
  monitor_changes:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out your forked repository
      - name: Checkout Fork
        uses: actions/checkout@v3
        with:
          ref: master
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0 # full history to allow merges

      # Step 2: Set Git identity
      - name: Set Git Identity
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions"
          echo "Git identity set"

      # Step 2: Add the upstream repository and fetch changes
      - name: Set Upstream Repository
        run: |
          echo "Adding upstream repository..."
          git remote add upstream https://github.com/electric-capital/crypto-ecosystems.git
          echo "Fetching from upstream..."
          git fetch upstream master
          echo "Current remotes:"
          git remote -v
          echo "Current branch:"
          git branch -v

      # Step 3: Check for Changes in Migrations Folder
      - name: Check for Changes in Migrations Folder
        id: changed_files
        run: |
          echo "Checking for changed files in migrations folder..."
          # Compare your fork with the upstream repository, focusing on migrations folder
          CHANGED_FILES=$(git diff --name-only HEAD upstream/master | grep '^migrations/' || true)
          HAS_CHANGES="false"
          echo "Changed Files in Migrations:"
          echo "$CHANGED_FILES"

          if [[ -n "$CHANGED_FILES" ]]; then
             HAS_CHANGES="true"
          fi

          echo "Has changes: $HAS_CHANGES"
          echo "has_changes=$HAS_CHANGES" >> $GITHUB_OUTPUT

      - name: Sync Fork with Upstream
        if: steps.changed_files.outputs.has_changes == 'true' # Only run if there are changes
        run: |
          echo "Starting sync with upstream..."
          # Merge upstream/master into the current branch
          git checkout master
          echo "Current branch after checkout:"
          git branch -v
          # Merge instead of hard-reset to keep local-only files like workflows
          git merge --no-edit upstream/master || true
          echo "Pushing merge to origin..."
          # Push the updated branch back to the fork without rewriting history
          git push origin master
          echo "Sync completed"

      - name: Run Export Command
        if: steps.changed_files.outputs.has_changes == 'true'
        run: |
          echo "Running export command..."
          chmod +x ./run.sh
          ./run.sh export exports.jsonl
          echo "Export completed"
          ls -la exports.jsonl

      - name: Configure AWS Credentials
        if: steps.changed_files.outputs.has_changes == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload to S3
        if: steps.changed_files.outputs.has_changes == 'true'
        run: |
          echo "Uploading exports.jsonl to S3..."
          
          aws s3 cp exports.jsonl s3://${{ secrets.S3_BUCKET_NAME }}/exports.jsonl
          
          echo "File uploaded to s3://${{ secrets.S3_BUCKET_NAME }}/exports.jsonl"

      # Final Step: Call API to notify about completed changes
      - name: Notify API
        if: steps.changed_files.outputs.has_changes == 'true'
        id: api_call
        env:
          API_URL: ${{ secrets.TALENT_PROTOCOL_API_URL }}
          API_KEY: ${{ secrets.TALENT_PROTOCOL_API_SECRET }}
        run: |
          echo "Preparing API call..."
          echo "Repository: ${{ github.repository }}"
          echo "Actor: ${{ github.actor }}"
          echo "Notifying API that new export is available on S3"
          
          # Make the API call with verbose output
          HTTP_CODE=$(curl -s -o response.json -w "%{http_code}" -X PUT $API_URL \
          -H "Content-Type: application/json" \
          -H "X-API-SECRET: $API_KEY")

          echo "HTTP Response Code: $HTTP_CODE"
          echo "API Response:"
          cat response.json
          
          if [[ "$HTTP_CODE" -ge 200 && "$HTTP_CODE" -lt 300 ]]; then
            echo "API call successful"
            echo "success=true" >> $GITHUB_OUTPUT
          else
            echo "API call failed with status $HTTP_CODE"
            echo "success=false" >> $GITHUB_OUTPUT
            exit 1
          fi